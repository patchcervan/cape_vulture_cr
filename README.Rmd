---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

# Cape Vulture Encounter Risk Map

<!-- badges: start -->
<!-- badges: end -->

In this repository you will find all the scripts used for processing the data and run the models that are used for building the encounter risk map for the Cape Vulture. There is a second repo that is used to produce the map from the fitted models. The simulation routines were separated from the fitting routines and packed into a package to be able to easily update the maps, when more/better information becomes available.

Some of the processing and fitting scripts take quite long to run. Therefore, run only if completely necessary and go find something to do. In addition, some of the scripts are better suited to run in a high performance computing environment (HPC), because the are very demanding of RAM memory. These will be flagged throughout the document, to proceed with care.

Note, paths to specific directories where data or outputs are hosted, need to be adapted to the user configuration.

## Pre-processing of tracking and colony data

```{r, eval=FALSE}

library(tidyverse)

# Load processing scripts directories
scripts <- dir("R/1_data_processing")

# Remove those used for the creation of templates.
# If you want to overwrite templates you will have to run those scripts directly
# (see data_processing/0_create_templates)
scripts <- scripts[str_detect(scripts, "0", negate = T)]

```


### Run processing scripts for specific birds

The objective of the data processing scripts is to bring all bird-tracking files
to a common standard. Different types of tags have their own characteristics, and
therefore, scripts are slightly different for different birds.

```{r, eval=FALSE}

proc <- scripts[1:18]

for(f in 1:length(proc)){
  
  # Need to reload scripts because of the rm() calls inside the scripts
  scripts <- dir("R/1_data_processing")
  scripts <- scripts[str_detect(scripts, "0", negate = T)]
  proc <- scripts[1:18]
  
  print(f)
  
  source(paste0("R/1_data_processing/", proc[f]))
  
}

# Also run fine processing: exclude certain birds, cut out certain periods, change ages for
# long term tracking, re-sample very high resolution tracks. Do before any colony processing
source("R/1_data_processing/3_fine_process.R")

```


### Prepare colony data

The colony data-processing scripts are used for bringing together colony data from
different sources and format them to a common standard. This entails finding
colonies that are repeated in the different sources to elaborate a unique list,
and calculate the average size of the colonies.

```{r, eval=FALSE}

# Load scripts
scripts <- dir("R/2_colony_processing")

# Run the processing scripts for colonies
for(s in seq_along(scripts)){
  
  print(s)
  
  # # Need to reload scripts because of the rm() calls inside the scripts
  scripts <- dir("R/2_colony_processing")
  source(paste0("R/2_colony_processing/", scripts[s]))
}

```

Once the colony data-processing scripts have been run, we can determine what
colonies each of the tracked vultures are using each year.

```{r, eval=FALSE}

# Run the colony process scripts in which we find the central places of the 
# vultures (WE SHOULD HAVE RAN "R/2_colony_finding/5_colony_finding.R" ALREADY)
source("R/1_data_processing/4_colony_process.R")

```


### Find movement modes

For some of the analysis we are interested in those tracking fixes that correspond
to moving birds. To separate movement from resting modes, we used either
Hidden Markov Models or finite mixture models. Running these models for all birds
takes really long, so consider running in an HPC. If ran in an HPC, there is a
second part in the script (from "Explore state proportions") that must be ran in
the local script if one wants to explore state proportions and things like that.
Do it manually.

```{r, eval=FALSE}
source("R/1_data_processing/5_move_mode_process.R")
```


### Prepare raster covariates

In this scripts we will prepare the covariates used for fitting the step-selection
and collision height model.

```{r, eval=FALSE}

# Create slope and ruggedness rasters from elevation. Also set sea level = 0
# Takes a while
source("R/3_prepare_covts/1_prep_covts_topo_rasters.R")

# Re-classify habitats and create a csv file with the codes
source("R/3_prepare_covts/2_prep_land_cover.R")

# Create a single shapefile with protected areas
source("R/3_prepare_covts/3_prep_prot_areas.R")

# Identify steep slopes to calculate distance to them later
# Might have to unload certain packages for it to run properly (best just re-start R)
# This variable did not go into the final model, it is only used for alternative
# models
source("R/3_prepare_covts/4_prep_steep_slopes.R")

# Create rasters with distance to steep slopes to use as covariates
# This takes very long, so don't run unless completely necessary.
# This variable did not go into the final model, it is only used for alternative
# models
source("R/3_prepare_covts/5_prep_dist_slp.R")

# Increase the resolution of distance to slopes and transform to meters.
# This variable did not go into the final model, it is only used for alternative
# models
source("R/3_prepare_covts/5a_red_dist_slp_m.R")

# Prepare the supplementary feeding sites file for processing
source("R/3_prepare_covts/6_prep_covts_restaurants.R")

```


### Run additional tracking data height processing scripts

Some tracking tags had heights wrap down to zero when they went above 2042. To
correct this and other issues producing nonsensical outliers we run the following
script. There will be some final processing in another script right before fitting

```{r, eval=FALSE}
source("R/1_data_processing/6_height_process.R")

```

Additionally, we run another script to detect anomalies in the distance travelled
by the birds. Some of the individuals analysed were rehabilitated birds that
might not exhibit a representative behaviour of the species in general.

```{r, eval=FALSE}

# Analyze distance traveled per day to try to detect anomalies
source("R/1_data_processing/7_dist_process.R")

```


### Create a database and prepare model-fitting data

```{r, eval=FALSE}

# Create a database with the new information extracted from the birds
source("R/1_data_processing/8_create_db_fit_ready.R")

```

Prepare data for fitting step-selection models.

```{r, eval=FALSE}

# Regularize trajectories, create pseudo-absences and annotating with covariates
# We tested different number of pseudo-absence points. For the final model we
# used 10 but for model selection, to save time and memory we used 5pp
source("R/4_ssf_model/1c_prep_ssf_data_10pp.R")

```

Prepare data for fitting collision height model

```{r, eval=FALSE}

# Annotating with covariates
source("R/5_height_model/1_prep_height_data.R")

# Final run of processing to fix some height records
source("R/5_height_model/1b_height_data_fix.R")

```


## Model fitting

We used cross-validation routines for model selection. These routines are memory
demanding and take long to run, because models need to fitted multiple times. It
is highly recommended to run these scripts in a high performance computing environment.

```{r, eval=FALSE}

# Run cross-validation for step-selection models
source("R/4_ssf_model/2_cv_hier_ssf.R")

# Fit best model
source("R/4_ssf_model/3_fit_hier_ssf.R")

```


```{r, eval=FALSE}

# Run cross-validation for collision height models
source("R/5_height_model/2_cv_hier_height.R")

# Fit best model
source("R/5_height_model/3_fit_hier_bern_height.R")

```


## Predicting utilization distributions

Cape Vulture simulation of activity is performed from the [vultRmap](https://github.com/patchcervan/vultRmap)
repository. There, we find the routines for predicting habitat preferences of the
species over new environments, simulate activity using these preferences and movement
contraints identified by the step-selection model, and finally produce utilization
distribution maps. All these routines can be found in the `analysis/update_ALL` directory.

Simulations are computationally very intensive and it is recommended to run them in a HPC.
We used a 20 core machine and 200GB of RAM to run simulations for all colonies and
it took a couple of days to run.

Very importantly, to be able to run these routines, we need the data found in yet
another directory called `vultRmap_data_aux`. This directory is not included in 
vultRmap because it contains sensitive tracking and colony data, and it will be
made available only by a motivated request.

Once all the pre-requirements are met, we can start producing maps. As before,
paths to specific directories need to be adapted to the user configuration.

```{r, eval=FALSE}

# Install the vultRmap package
remotes::install_github("patchcervan/vultRmap")

```


```{r, eval=FALSE}

# Run simulations around all identified colonies in a HPC environment
source("analysis/update_ALL/1_ssf_sims_all.R")

# Predict flight height for simulated Cape Vulture locations
source("analysis/update_ALL/1_hgt_risk_all.R")

# Smooth utilization distribution using GAMs
source("analysis/update_ALL/3_ssf_gam_all.R")

# Smooth utilization distribution at collision risk height GAMs
source("analysis/update_ALL/4_hgt_gam_all.R")

```


## Producing encounter risk maps

```{r, eval=FALSE}

# Compute cumulative UD and produce raster maps
source("analysis/update_ALL/5_make_all_risk_maps.R")

# Save maps in HTML formats
source("analysis/update_ALL/6_make_all_html_maps.R")

```


## Updating encounter risk maps

If new colony and/or roost data is collected, the first thing we need to do, before updating the encounter risk maps, is to update our colony database. This will be done through the [vultRmap](https://github.com/patchcervan/vultRmap) package.

At this point is really IMPORTANT TO MAKE A COPY OF THE COLONY DATABASE BEFORE MAKING ANY CHANGES. The following procedures will modify the database without the possibility of going back to what it was.

The function `updateColonyCount()` is the workhorse function to update colony data. See `help(updateColonyCount)` for details. 

The script `vultRmap/analysis/0_colony_updates/` is used to keep track of the updates made to the database so far. In this file there are some examples of updates that had be done before the paper was published.

Once the updates to the colony database are completed, we must proceed to produce new Cape Vulture activity simulations for those colonies that we need updates for.

The procedure for simulating around new colonies would be the same used in the previous section. However, in this case we will have to specify the colonies we want to simulate activity for. For this we go to `vultRmap/analysis/update_ONE` and run the two scripts in this directory, modifying the functions `1_ssf_sim` and `2_hgt_sim` specifying the colony codes we want simulations for. For example, the following code will simulate activity around colonies "cvcol009" and "cvcol115".

```{r, eval=FALSE}
sim_ssf(colonies = c("cvc009", "cvcol115"),
        out_dir = "/home/vultRmap/sims",
        data_dir = "/home/vultRmap_data_aux",
        seeds = c(6548, 89745),
        totalsteps = 1000,
        ncores = 4,
        dist_lim = 500,
        sample_coefs = 4)
```

Similarly, this code will simulate flight height for the activity simulations

```{r,eval=FALSE}
sim_height_risk(colonies = c("cvc009", "cvcol115"),
                data_dir = "../vultRmap_data_aux/",
                sims_dir = "../vultRmap_data_aux/col_sims/",
                out_dir = "../vultRmap_data_aux/col_hgt_sims/",
                ncoefs = 40,
                seed = 87634)
```

As previously mentioned, activity simulations are computationally demanding, so
both scripts use the capabilities of the `furrr` package to run the simulations in
parallel. It is recommended to use a machine with at least 4 cores and 16 GB of 
RAM for running simulations for individual colonies.

After simulating activity for the new colonies, we need to smooth the UDs for all
colonies combined, just as we did earlier.

```{r, eval=FALSE}

# Smooth utilization distribution using GAMs
source("analysis/update_ALL/3_ssf_gam_all.R")

# Smooth utilization distribution at collision risk height GAMs
source("analysis/update_ALL/4_hgt_gam_all.R")

```

And produce the encounter risk maps with the new information.

```{r, eval=FALSE}

# Compute cumulative UD and produce raster maps
source("analysis/update_ALL/5_make_all_risk_maps.R")

# Save maps in HTML formats
source("analysis/update_ALL/6_make_all_html_maps.R")

```

